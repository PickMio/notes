
[字符集和字符编码详解](http://www.cnblogs.com/skynet/archive/2011/05/03/2035105.html)
[字符集与编码的恩怨情仇](http://2wildkids.com/2016/10/12/%E5%AD%97%E7%AC%A6%E9%9B%86%E4%B8%8E%E7%BC%96%E7%A0%81%E7%9A%84%E6%81%A9%E6%80%A8%E6%83%85%E4%BB%87/)
作者：匿名用户
链接：https://www.zhihu.com/question/24572900/answer/132107230
来源：知乎
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

1，utf 编码方式的设计初衷主要就是节省，utf8 因为兼容ascii，可以使用一个字节表示英语世界常用字符，
    比较省空间和带宽。utf16就比较尴尬，因为使用了宽字符，对英语世界的用户来说，
    很可能不但不节省还浪费空间和带宽。至于中文世界嘛，用 utf8 其实有点浪费资源，
    用 utf8 主要是软件栈的原因。很多软件因为是英语世界的人开发的，对 utf8 支持的最好。
2，utf16 因为使用两个字节为单位，所以分大尾和小尾，即 utf16 be 和 utf16 le。这个东西有点讨厌，很多人其实并不知道 utf16    
    有两种，他们也搞不清楚自己把数据存成了 be 还是 le。要么你写程序的时候兼容掉，要么就要求用户分清楚大小尾。
    问题是不写程序的人谁会关注这个？
3，对于编程来说，最友好的编码是 utf32。由于 utf32 表示任何字符都用 4 字节，
    读到内存中是个均匀的整形数组，于是我们可以很方便地随机访问任何一个字符。
    utf8 就不行，你想访问一个字符串中的第 n 个字符，utf32 直接偏移 n 个整形距离即可，
    utf8 得从第一个字节一个字一个字地往后蹦，非常蛋疼。
4，所以最理想的文字处理方式是用 utf8 存储和传输，程序读到内存里转为 utf32 处理。
